{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNck/KPKt4rf4S9jthskZaW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amanda-pinheiro/Primeiro-modelo-LLM/blob/main/ChatBot_Imers%C3%A3o_IA_Alura_%2B_Google.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalando SDK do Google"
      ],
      "metadata": {
        "id": "Es-8DHOk4m3p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nxilnGkcvEdY"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q google-generativeai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Python SDK"
      ],
      "metadata": {
        "id": "VZOL1Grk4zMA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "GOOGLE_API_KEY='your_key'\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "2jtwwenb42Jl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Listar os Modelos dosponíveis"
      ],
      "metadata": {
        "id": "afU20SWs5clt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for m in genai.list_models():\n",
        "  if 'generateContent' in m.supported_generation_methods:\n",
        "    print(m.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "_oH0f0Bn5aA3",
        "outputId": "52bad256-8a0f-4380-e82b-c9748698bacf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-1.0-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-pro\n",
            "models/gemini-pro-vision\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configurações"
      ],
      "metadata": {
        "id": "L4DXyMMo8p-C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generation_config = {\n",
        "    \"candidate_count\": 1,\n",
        "    \"temperature\": 0.5}\n",
        "\n",
        "safety_settings = {\n",
        "    \"HARASSMENT\": \"BLOCK_NONE\",\n",
        "    \"HATE\": \"BLOCK_NONE\",\n",
        "    \"SEXUAL\": \"BLOCK_NONE\",\n",
        "    \"DANGEROUS\": \"BLOCK_NONE\"\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gr2nrjKF6vF4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inicializando  Modelo"
      ],
      "metadata": {
        "id": "5WQPbZdv8tla"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel(model_name = \"gemini-1.0-pro\",\n",
        "                              generation_config = generation_config,\n",
        "                              safety_settings = safety_settings)\n"
      ],
      "metadata": {
        "id": "et1Vy3r781D8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Response"
      ],
      "metadata": {
        "id": "H7M9U19y9l8A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\"Vamos aprender sobre IA. Me dê sugestões.\")\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "Q491qDv49n51",
        "outputId": "51f12998-1226-44ee-e79d-4fa00e49c7ad",
        "collapsed": true
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Recursos Online:**\n",
            "\n",
            "* **Coursera:** Cursos sobre IA, aprendizado de máquina e aprendizado profundo\n",
            "* **edX:** Cursos sobre IA, visão computacional e processamento de linguagem natural\n",
            "* **MIT OpenCourseWare:** Aulas e materiais do curso sobre IA do MIT\n",
            "* **Stanford Online:** Cursos sobre IA, aprendizado de máquina e robótica\n",
            "* **Kaggle:** Plataforma para aprender e praticar IA por meio de competições e conjuntos de dados\n",
            "\n",
            "**Livros:**\n",
            "\n",
            "* **Inteligência Artificial: Uma Abordagem Moderna (3ª Edição)** por Stuart Russell e Peter Norvig\n",
            "* **Aprendizado de Máquina (4ª Edição)** por Ethem Alpaydin\n",
            "* **Aprendizado Profundo (2ª Edição)** por Ian Goodfellow, Yoshua Bengio e Aaron Courville\n",
            "* **Visão Computacional (2ª Edição)** por Richard Szeliski\n",
            "* **Processamento de Linguagem Natural (2ª Edição)** por Daniel Jurafsky e James H. Martin\n",
            "\n",
            "**Revistas e Publicações:**\n",
            "\n",
            "* **Nature Machine Intelligence:** Revista científica que cobre pesquisas de ponta em IA\n",
            "* **IEEE Transactions on Pattern Analysis and Machine Intelligence:** Revista técnica que publica pesquisas sobre visão computacional, aprendizado de máquina e reconhecimento de padrões\n",
            "* **International Journal of Artificial Intelligence Tools:** Revista que abrange todos os aspectos da IA, incluindo teoria, algoritmos e aplicações\n",
            "* **ACM Transactions on Intelligent Systems and Technology:** Revista que publica pesquisas sobre sistemas inteligentes, incluindo IA, aprendizado de máquina e robótica\n",
            "\n",
            "**Comunidades e Eventos:**\n",
            "\n",
            "* **Associação para o Avanço da Inteligência Artificial (AAAI):** Organização profissional que promove o avanço da IA\n",
            "* **Conferência Internacional Conjunta sobre Inteligência Artificial (IJCAI):** Conferência anual que reúne pesquisadores e profissionais da IA\n",
            "* **Conferência sobre Sistemas de Processamento de Informação Neural (NeurIPS):** Conferência anual focada em aprendizado de máquina e aprendizado profundo\n",
            "* **Encontros e Grupos de IA Locais:** Procure por grupos locais em sua área para se conectar com outros entusiastas da IA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Criando o Chat\n",
        "\n",
        "while True:\n",
        "  prompt = input (\"Esperando prompt: \" )\n",
        "  response = chat.send_message(prompt)\n",
        "  print(\"Resposta: \", response.text, \"\\n\")\n",
        "  if prompt in \"fim\":\n",
        "    break"
      ],
      "metadata": {
        "id": "RMueq8YH-GYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat = model.start_chat(history=[])"
      ],
      "metadata": {
        "id": "vHSDPuZ6-IVO"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "  prompt = input (\"Esperando prompt: \" )\n",
        "  response = chat.send_message(prompt)\n",
        "  print(\"Resposta: \", response.text, \"\\n\")\n",
        "  if prompt in \"fim\":\n",
        "    break"
      ],
      "metadata": {
        "id": "vZg679gXHG95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Melhorando a visualização"
      ],
      "metadata": {
        "id": "zapM6qebHYM6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "def to_markdown(text):\n",
        "  text = text.replace('*', ' *')\n",
        "  return Markdown(textwrap.indent(text, ' >', predicate=lambda _: True))\n",
        "\n",
        "#Imprimindo o histórico\n",
        "\n",
        "for message in chat.history:\n",
        "  display(to_markdown(f'**{message.role}**: {message.parts[0].text}'))\n",
        "  print('-' * 50)\n"
      ],
      "metadata": {
        "id": "aINqZJRPHaMf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}